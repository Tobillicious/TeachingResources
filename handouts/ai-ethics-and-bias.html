<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Ethics and Bias</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="../css/main.css">
</head>
<body class="bg-gray-100">
    <div class="page-container" data-tags="digital-tech,ai,ethics,civics">
        <header class="text-center border-b-2 border-gray-200 pb-4 mb-6">
            <h1 class="text-3xl font-bold text-gray-800">Case Study: AI Ethics and Bias</h1>
            <p class="text-lg text-gray-600 mt-1">When Good Data Goes Bad</p>
        </header>
        <main>
            <section class="mb-6">
                <div class="bg-red-50 p-4 rounded-xl border border-red-200">
                    <h2 class="text-xl font-bold text-red-800 mb-2">The Problem of Bias</h2>
                    <p class="text-gray-700">An AI model is only as good as the data it's trained on. Because LLMs are trained on vast amounts of text from the internet, they learn the biases that are present in that text. If the data reflects historical inequalities or stereotypes, the AI will learn and can even amplify those biases.</p>
                </div>
            </section>
            <section class="mb-6">
                <h2 class="text-2xl font-bold text-gray-800 mb-4">Case Study: Biased Hiring Tool</h2>
                <div class="bg-white p-4 rounded-lg shadow">
                    <p class="text-gray-700">A major tech company created an AI tool to help them screen CVs. The goal was to find the best candidates. They trained the model on the CVs of people they had hired over the last 10 years. However, because the company had historically hired more men than women, the AI learned that male candidates were preferable. It started penalizing CVs that included the word "women's" (e.g., "women's chess club captain") and downgrading graduates from all-women's colleges. The company had to scrap the tool.</p>
                </div>
            </section>
             <section>
                <h2 class="text-2xl font-bold text-gray-800 mb-4">Critical Thinking</h2>
                <div class="bg-white p-4 rounded-lg shadow">
                    <p class="font-semibold mb-2">Who is responsible for the bias in the AI hiring tool? The programmers? The company? The historical data? Explain your reasoning.</p>
                    <div class="h-24 bg-gray-50 border border-gray-300 rounded-md p-2"></div>
                </div>
            </section>
        </main>
    </div>
</body>
</html>